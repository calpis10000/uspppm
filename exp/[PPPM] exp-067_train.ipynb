{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1654287731717,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"ODefLcHTuzkZ","outputId":"215b91bd-2b9d-447b-b09f-99a7fe9ff0a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Jun  3 20:22:10 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   57C    P0    52W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11228,"status":"ok","timestamp":1654287756755,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"bfwZudNPMeuX","outputId":"e7c32ae5-76de-4696-9078-9834d91d567f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers==4.19.1 in /usr/local/lib/python3.7/dist-packages (4.19.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (3.7.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (4.64.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (2019.12.20)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (0.7.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (4.11.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.1) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.1) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.1) (3.8.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (1.24.3)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece==0.1.96 in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}],"source":["!pip install transformers==4.19.1\n","!pip install sentencepiece==0.1.96"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-O7K0BPfBHO"},"outputs":[],"source":["# ----------------------------------------------\n","# Load Libraries\n","# ----------------------------------------------\n","import pathlib\n","from pathlib import Path\n","import sys\n","import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import BertForSequenceClassification, BertConfig, BertModel\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import tqdm\n","\n","import gc\n","gc.enable()"]},{"cell_type":"markdown","metadata":{"id":"lLCSxR_tfbtn"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nv0CdG49fTXR"},"outputs":[],"source":["class CFG:\n","    exp_id = 'exp067'\n","    input_path = 'input/pppm/'\n","    cpc_path = 'cpc_texts/'\n","    model_path = 'roberta-large'\n","    out_base = '/content/drive/MyDrive/Colab_Files/kaggle/pppm/output'\n","    out_path = f'{out_base}/{exp_id}'\n","    scores_path = f'{out_path}/scores'\n","    \n","    debug = False\n","    fold1_only = False\n","    upload_dataset = True\n","    debug_size = 100\n","    log_interval = 1822 # 未使用\n","    seed = 42\n","    max_len = 92\n","    learning_rate = 2e-5\n","    weight_decay = 0.01\n","    lr_decay = 0.96\n","    num_classes = 1\n","    num_fold = 4\n","    epochs = 5\n","    train_batch_size = 16\n","    valid_batch_size = 16\n","    gradient_accumulation_step = 1\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    if debug:\n","      epochs = 1\n","      upload_dataset = False\n","\n","    if fold1_only:\n","      upload_dataset = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2LXX-6iO5Re"},"outputs":[],"source":["!mkdir -p {CFG.out_path}\n","!mkdir -p {CFG.scores_path}"]},{"cell_type":"markdown","metadata":{"id":"1M170jR7fcj8"},"source":["# Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iK90exIjNouV"},"outputs":[],"source":["# ----------------------------------------------\n","# Set SEED\n","# ----------------------------------------------\n","# seed\n","SEED = CFG.seed\n","def set_seed(SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    \n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    \n","set_seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1654287760997,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"yOJIHPpJikW3","outputId":"bf6177cf-65a1-488e-a58c-a659cebdd3b8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1ad0f074-06b4-41a3-8d6c-951d519d59a8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ad0f074-06b4-41a3-8d6c-951d519d59a8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1ad0f074-06b4-41a3-8d6c-951d519d59a8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1ad0f074-06b4-41a3-8d6c-951d519d59a8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  \n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  "]},"metadata":{},"output_type":"display_data"}],"source":["train_df = pd.read_csv(f\"{CFG.input_path}train.csv\")\n","# https://www.kaggle.com/code/gauravbrills/folds-dump-the-two-paths-fix\n","cpc_texts = torch.load(CFG.cpc_path+\"cpc_texts_fixed.pth\")\n","train_df['context_text'] = train_df['context'].map(cpc_texts)\n","display(train_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3147,"status":"ok","timestamp":1654287764139,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"OESlEphOfUcZ","outputId":"0b78cbfd-d3ab-425e-f4b2-261a4aef20ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["550 183\n","549 184\n","550 183\n","550 183\n"]}],"source":["!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train_df, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.num_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train_df = train_df.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1654287764140,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"sGikoiA9HfG2","outputId":"da3bc4ea-20eb-4763-b235-be7150c48d97"},"outputs":[{"data":{"text/plain":["0    9379\n","1    8860\n","2    8612\n","3    9622\n","Name: fold, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_df['fold'].value_counts().sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654287764141,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"qskUdzrFG5uq","outputId":"ce3788eb-84ff-4b7a-ea3c-1af8799df70e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(36473, 7)\n"]},{"data":{"text/html":["\n","  <div id=\"df-7e631fc0-95f6-4fbb-b73c-99252944cc5f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e631fc0-95f6-4fbb-b73c-99252944cc5f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7e631fc0-95f6-4fbb-b73c-99252944cc5f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7e631fc0-95f6-4fbb-b73c-99252944cc5f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  fold  \n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654287764141,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"npXkzRTkDmL4","outputId":"02d84021-b171-4070-cb26-acea0fe81daf"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"train_df['con_grp'] = train_df['context'].map(lambda x: x[:1])\\ntrain_df.groupby('fold')['con_grp'].value_counts().sort_index()\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"train_df['con_grp'] = train_df['context'].map(lambda x: x[:1])\n","train_df.groupby('fold')['con_grp'].value_counts().sort_index()\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BTOQ441fgW6"},"outputs":[],"source":["train_df['input'] = train_df['anchor'] + '[SEP]' + train_df['target'] + '[SEP]' + train_df['context_text']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654287764142,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"tjNzFNT8noYm","outputId":"af241ac2-c1c5-45f3-c85c-3306cee9c5fb"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-39b8e0a9-9156-44a8-b2ba-75a688ffd2c1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>fold</th>\n","      <th>input</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39b8e0a9-9156-44a8-b2ba-75a688ffd2c1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-39b8e0a9-9156-44a8-b2ba-75a688ffd2c1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-39b8e0a9-9156-44a8-b2ba-75a688ffd2c1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  fold  \\\n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","\n","                                               input  \n","0  abatement[SEP]abatement of pollution[SEP]HUMAN...  \n","1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...  \n","2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...  \n","3  abatement[SEP]eliminating process[SEP]HUMAN NE...  \n","4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"aAVnHp8Ofsso"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1ADD0EJfgUj"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1654287768184,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"h30ob5ihINOq","outputId":"59622e5d-1a87-420f-ad06-7faf481513d7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\ntoken_len = train_df['input'].map(lambda x: tokenizer(x)['input_ids'].__len__())\\ndisplay(token_len.describe())\\ntoken_len.hist(bins=100)\\n\""]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# トークン長分布の確認\n","\"\"\"\n","token_len = train_df['input'].map(lambda x: tokenizer(x)['input_ids'].__len__())\n","display(token_len.describe())\n","token_len.hist(bins=100)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"n5qNQG7XfvtE"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5JyZ3RnfgRr"},"outputs":[],"source":["def prepare_input(tokenizer, text):\n","    inputs = tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=CFG.max_len,\n","                           padding=\"max_length\",\n","                           truncation=True,\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, df):\n","        self.inputs = df['input'].values\n","        self.label = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, item):\n","        inputs = self.inputs[item]\n","        label = self.label[item]\n","        outputs = prepare_input(tokenizer, inputs)\n","        outputs['label'] = torch.tensor(label, dtype=torch.float32)\n","\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"ikO_UwLyf1KF"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTGp5AHE2e4o"},"outputs":[],"source":["# ----------------------------------------------\n","# Model\n","# ----------------------------------------------\n","class AttentionHead(nn.Module):\n","    def __init__(self, in_features, hidden_dim, num_targets):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.middle_features = hidden_dim\n","        self.W = nn.Linear(in_features, hidden_dim)\n","        self.V = nn.Linear(hidden_dim, 1)\n","        self.out_features = hidden_dim\n","\n","    def forward(self, features):\n","        att = torch.tanh(self.W(features))\n","        score = self.V(att)\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * features\n","        context_vector = torch.sum(context_vector, dim=1)\n","\n","        return context_vector\n","\n","class PPPMModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.num_reinit_layers = 6\n","        self.config = AutoConfig.from_pretrained(CFG.model_path)\n","        self.config.attention_probs_dropout_prob = 0.0\n","        self.config.hidden_dropout_prob = 0.0\n","        self.pre_model = AutoModel.from_pretrained(CFG.model_path, config=self.config)\n","        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size,1)\n","        #self.dropout = nn.Dropout(0.3)\n","        self.regressor = nn.Linear(self.config.hidden_size, CFG.num_classes)\n","        #self.initialize()\n","    \n","    def forward(self, inputs):\n","        pre_out = self.pre_model(**inputs)\n","        x = pre_out[0]\n","        x = self.head(x)\n","        x = self.regressor(x)\n","        return x\n","  \n","    def initialize(self):\n","      for i in range(self.num_reinit_layers):\n","          self.pre_model.encoder.layer[-(1 + i)].apply(self._init_weight)\n","\n","    def _init_weight(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.pre_model.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfqjFdzk3yd3"},"outputs":[],"source":["# ----------------------------------------------\n","# func: valid, predict\n","# ----------------------------------------------\n","def predict(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), CFG.num_classes))\n","    idx = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","          inputs = {}\n","          for k, v in data.items():\n","            inputs[k] = v.to(CFG.device)            \n","          output = model(inputs)\n","          result[idx:idx + output.shape[0], :] = output.to('cpu')\n","          idx += output.shape[0]\n","            \n","    return result\n","\n","\n","def valid_mse(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), CFG.num_classes))\n","    idx = 0\n","    mse_sum = 0\n","    bar = tqdm(dataloader, total=len(dataloader))\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(bar):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          label = data['label'].to(CFG.device)          \n","          output = model(inputs)\n","          result[idx:idx + output.shape[0], :] = output.to('cpu')\n","          idx += output.shape[0]\n","\n","          mse_sum += nn.MSELoss(reduction='sum')(output.flatten(), label).item()\n","            \n","    return mse_sum/(len(dataloader.dataset)), result.reshape(len(result))\n","\n","\n","def metric_pearson(predictions, labels):\n","    pearson = np.corrcoef(predictions, labels)[0][1]       \n","    return pearson"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0HFdCII38i_"},"outputs":[],"source":["# ----------------------------------------------\n","# func: train\n","# ----------------------------------------------\n","def train_fn(\n","    model,\n","    save_path,\n","    train_loader,\n","    val_loader,\n","    optimizer,\n","    scheduler=None,\n","    num_epochs=CFG.epochs\n","):\n","\n","    best_score = 0\n","    best_epoch = 0\n","    running_loss = 0.0\n","    dataset_size = 0\n","    log_interval = CFG.log_interval\n","    oof_preds = None\n","\n","    start = time.time()\n","\n","    for epoch in range(num_epochs):\n","        val_score = None\n","        model.train()\n","        bar = tqdm(train_loader, total=len(train_loader))\n","        for batch_idx, data in enumerate(bar):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          label = data['label'].to(CFG.device)\n","          batch_size = label.size(0)\n","\n","          output = model(inputs)\n","          loss = nn.MSELoss()(output.flatten(), label)\n","          loss = loss / CFG.gradient_accumulation_step\n","\n","          loss.backward()\n","\n","          if (batch_idx + 1) % CFG.gradient_accumulation_step == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            if scheduler:\n","                scheduler.step()\n","\n","          if CFG.debug == True:\n","            if (batch_idx > 0) & (batch_idx % CFG.debug_size == 0):\n","                break\n","\n","          running_loss += (loss.item() * batch_size)\n","          dataset_size += batch_size            \n","          total_loss = running_loss / dataset_size\n","          bar.set_postfix(Epoch=epoch, Loss=loss.item(), TotalLoss=total_loss, LR=optimizer.param_groups[0]['lr'])\n","\n","        val_start = time.time()\n","        val_score, predictions = valid_mse(model, val_loader)\n","        pearson = metric_pearson(predictions, val_loader.dataset.label)\n","        print(f\"Epoch {epoch+1}, Step {batch_idx+1}, train_loss: {loss:0.5f}, val_loss: {val_score:0.5f}, pearson: {pearson:0.5f}\")\n","        if pearson > best_score:\n","            print(f\"Model Inproved: {best_score} ----> {pearson}\")\n","            best_score = pearson\n","            oof_preds = predictions\n","            torch.save(model.state_dict(), save_path)\n","        print(f\"validation elasped time: {time.time() - val_start: 0.3}\")\n","\n","    print(f\"total elasped time: {time.time() - start: 0.3}\")\n","    start = time.time()\n","\n","    return best_score, oof_preds\n","\n","# ----------------------------------------------\n","# create optimizer\n","# ----------------------------------------------\n","def create_optimizer(model):\n","    named_params = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optim_params = []\n","    for idx_, (name_, params_) in enumerate(named_params):\n","        weight_decay = 0 if name_ in no_decay else 0.01\n","        optim_params.append({'params':params_,\n","                            'weight_decay': weight_decay,\n","                            })\n","\n","    return AdamW(optim_params)\n","\n","\n","# https://www.ai-shift.co.jp/techblog/2145\n","def create_optimizer_grouped_parameters(model):\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": 1e-3,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, 'pre_model').embeddings] + list(getattr(model, 'pre_model').encoder.layer)\n","    layers.reverse()\n","    lr = CFG.learning_rate\n","    for layer in layers:\n","        lr *= CFG.lr_decay\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": CFG.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return AdamW(optimizer_grouped_parameters)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"gxz1VyLy6wkn","outputId":"f8d1cfa9-1115-409c-ff84-bea8f2482bb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** FOLD 1 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","100%|██████████| 1693/1693 [13:57<00:00,  2.02it/s, Epoch=0, LR=0.000913, Loss=0.029, TotalLoss=0.0343]\n","100%|██████████| 587/587 [01:25<00:00,  6.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1693, train_loss: 0.02899, val_loss: 0.02885, pearson: 0.79166\n","Model Inproved: 0 ----> 0.7916612241529974\n","validation elasped time:  91.2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [13:56<00:00,  2.03it/s, Epoch=1, LR=0.000665, Loss=0.0164, TotalLoss=0.0255]\n","100%|██████████| 587/587 [01:25<00:00,  6.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1693, train_loss: 0.01638, val_loss: 0.02524, pearson: 0.79142\n","validation elasped time:  85.1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [13:57<00:00,  2.02it/s, Epoch=2, LR=0.000353, Loss=0.00595, TotalLoss=0.0199]\n","100%|██████████| 587/587 [01:25<00:00,  6.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1693, train_loss: 0.00595, val_loss: 0.02483, pearson: 0.79393\n","Model Inproved: 0.7916612241529974 ----> 0.7939309750767866\n","validation elasped time:  90.9\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [13:57<00:00,  2.02it/s, Epoch=3, LR=9.77e-5, Loss=0.003, TotalLoss=0.0159]\n","100%|██████████| 587/587 [01:25<00:00,  6.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1693, train_loss: 0.00300, val_loss: 0.02491, pearson: 0.79812\n","Model Inproved: 0.7939309750767866 ----> 0.7981230807332561\n","validation elasped time:  91.2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [13:57<00:00,  2.02it/s, Epoch=4, LR=0, Loss=0.000313, TotalLoss=0.0131]\n","100%|██████████| 587/587 [01:24<00:00,  6.91it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1693, train_loss: 0.00031, val_loss: 0.02521, pearson: 0.79557\n","validation elasped time:  85.0\n","total elasped time:  4.63e+03\n","[0.7981230807332561]\n","Mean: 0.7981230807332561\n","*** FOLD 2 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1725/1725 [14:13<00:00,  2.02it/s, Epoch=0, LR=0.000913, Loss=0.0187, TotalLoss=0.0365]\n","100%|██████████| 554/554 [01:20<00:00,  6.91it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1725, train_loss: 0.01875, val_loss: 0.02856, pearson: 0.78137\n","Model Inproved: 0 ----> 0.7813744375280561\n","validation elasped time:  86.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [14:15<00:00,  2.02it/s, Epoch=1, LR=0.000665, Loss=0.0171, TotalLoss=0.0265]\n","100%|██████████| 554/554 [01:20<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1725, train_loss: 0.01712, val_loss: 0.02912, pearson: 0.78761\n","Model Inproved: 0.7813744375280561 ----> 0.7876126281981025\n","validation elasped time:  86.0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [14:14<00:00,  2.02it/s, Epoch=2, LR=0.000353, Loss=0.00456, TotalLoss=0.0207]\n","100%|██████████| 554/554 [01:20<00:00,  6.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1725, train_loss: 0.00456, val_loss: 0.02745, pearson: 0.78750\n","validation elasped time:  80.7\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [14:14<00:00,  2.02it/s, Epoch=3, LR=9.77e-5, Loss=0.00148, TotalLoss=0.0166]\n","100%|██████████| 554/554 [01:20<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1725, train_loss: 0.00148, val_loss: 0.02566, pearson: 0.78889\n","Model Inproved: 0.7876126281981025 ----> 0.788889529750942\n","validation elasped time:  86.1\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [14:14<00:00,  2.02it/s, Epoch=4, LR=0, Loss=0.0003, TotalLoss=0.0137]\n","100%|██████████| 554/554 [01:20<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1725, train_loss: 0.00030, val_loss: 0.02630, pearson: 0.78608\n","validation elasped time:  80.5\n","total elasped time:  4.69e+03\n","[0.7981230807332561, 0.788889529750942]\n","Mean: 0.793506305242099\n","*** FOLD 3 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1741/1741 [14:23<00:00,  2.02it/s, Epoch=0, LR=0.000913, Loss=0.0238, TotalLoss=0.0354]\n","100%|██████████| 539/539 [01:18<00:00,  6.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1741, train_loss: 0.02379, val_loss: 0.02741, pearson: 0.77882\n","Model Inproved: 0 ----> 0.7788227631184932\n","validation elasped time:  84.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [14:23<00:00,  2.02it/s, Epoch=1, LR=0.000665, Loss=0.0252, TotalLoss=0.0261]\n","100%|██████████| 539/539 [01:18<00:00,  6.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1741, train_loss: 0.02519, val_loss: 0.02878, pearson: 0.79298\n","Model Inproved: 0.7788227631184932 ----> 0.7929763072531734\n","validation elasped time:  84.7\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [14:23<00:00,  2.02it/s, Epoch=2, LR=0.000352, Loss=0.00758, TotalLoss=0.0204]\n","100%|██████████| 539/539 [01:18<00:00,  6.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1741, train_loss: 0.00758, val_loss: 0.02461, pearson: 0.80708\n","Model Inproved: 0.7929763072531734 ----> 0.8070817214234481\n","validation elasped time:  84.2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [14:23<00:00,  2.02it/s, Epoch=3, LR=9.76e-5, Loss=0.00597, TotalLoss=0.0164]\n","100%|██████████| 539/539 [01:18<00:00,  6.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1741, train_loss: 0.00597, val_loss: 0.02454, pearson: 0.80393\n","validation elasped time:  78.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [14:23<00:00,  2.02it/s, Epoch=4, LR=0, Loss=0.00024, TotalLoss=0.0135]\n","100%|██████████| 539/539 [01:18<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1741, train_loss: 0.00024, val_loss: 0.02476, pearson: 0.80254\n","validation elasped time:  78.3\n","total elasped time:  4.73e+03\n","[0.7981230807332561, 0.788889529750942, 0.8070817214234481]\n","Mean: 0.7980314439692154\n","*** FOLD 4 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1678/1678 [13:52<00:00,  2.02it/s, Epoch=0, LR=0.000913, Loss=0.0478, TotalLoss=0.0402]\n","100%|██████████| 602/602 [01:27<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1678, train_loss: 0.04781, val_loss: 0.02945, pearson: 0.75876\n","Model Inproved: 0 ----> 0.7587614238050311\n","validation elasped time:  93.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [13:51<00:00,  2.02it/s, Epoch=1, LR=0.000665, Loss=0.0253, TotalLoss=0.0288]\n","100%|██████████| 602/602 [01:27<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1678, train_loss: 0.02530, val_loss: 0.02958, pearson: 0.76017\n","Model Inproved: 0.7587614238050311 ----> 0.7601720103799546\n","validation elasped time:  93.0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [13:52<00:00,  2.02it/s, Epoch=2, LR=0.000353, Loss=0.0068, TotalLoss=0.0224]\n","100%|██████████| 602/602 [01:27<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1678, train_loss: 0.00680, val_loss: 0.02886, pearson: 0.76611\n","Model Inproved: 0.7601720103799546 ----> 0.7661109996932539\n","validation elasped time:  93.0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [13:51<00:00,  2.02it/s, Epoch=3, LR=9.77e-5, Loss=0.00503, TotalLoss=0.0179]\n","100%|██████████| 602/602 [01:27<00:00,  6.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1678, train_loss: 0.00503, val_loss: 0.02818, pearson: 0.76832\n","Model Inproved: 0.7661109996932539 ----> 0.7683177676480741\n","validation elasped time:  93.4\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [13:51<00:00,  2.02it/s, Epoch=4, LR=0, Loss=0.000585, TotalLoss=0.0148]\n","100%|██████████| 602/602 [01:27<00:00,  6.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1678, train_loss: 0.00059, val_loss: 0.02803, pearson: 0.76595\n","validation elasped time:  87.5\n","total elasped time:  4.62e+03\n","[0.7981230807332561, 0.788889529750942, 0.8070817214234481, 0.7683177676480741]\n","Mean: 0.7906030248889301\n"]}],"source":["# ----------------------------------------------\n","# Main Loop\n","# ----------------------------------------------\n","val_scores = []\n","oof_df = pd.DataFrame()\n","\n","for fold in range(CFG.num_fold): \n","    print(f\"*** FOLD {fold+1} / {CFG.num_fold}***\")\n","\n","    save_path = f\"{CFG.out_path}/model_{fold+1}.pth\"\n","\n","    train_data = train_df[train_df['fold'] != fold]\n","    valid_data = train_df[train_df['fold'] == fold]\n","    train_set = TrainDataset(train_data)\n","    valid_set = TrainDataset(valid_data)\n","\n","    train_loader = DataLoader(train_set,\n","                            batch_size=CFG.train_batch_size,\n","                            shuffle=True,\n","                            drop_last=True,\n","                            num_workers=2,\n","                            pin_memory=True)\n","    valid_loader = DataLoader(valid_set,\n","                            batch_size=CFG.valid_batch_size,\n","                            shuffle=False,\n","                            drop_last=False,\n","                            num_workers=2,\n","                            pin_memory=True)\n","\n","    model = PPPMModel().to(CFG.device)\n","    #optimizer = create_optimizer(model)\n","    optimizer = create_optimizer_grouped_parameters(model)\n","    #optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)\n","    scheduler = get_cosine_schedule_with_warmup(\n","        optimizer,\n","        num_training_steps=CFG.epochs*len(train_loader),\n","        num_warmup_steps=100\n","    )\n","\n","    val_score, val_preds = train_fn(model, save_path, train_loader, valid_loader, optimizer, scheduler=scheduler)\n","\n","    val_scores.append(val_score)\n","    valid_data['preds'] = val_preds\n","    oof_df = pd.concat([oof_df, valid_data])\n","\n","    del model\n","    torch.cuda.empty_cache()\n","\n","    print(val_scores)\n","    print(\"Mean:\", np.array(val_scores).mean())\n","    if CFG.fold1_only == True:\n","        if fold == 0:\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nz0KfPOAXBbi","outputId":"29af0dde-a915-41f0-8f13-ced099d7b01a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'for batch_idx, data in enumerate(valid_loader):\\n  print(batch_idx)\\n'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"for batch_idx, data in enumerate(valid_loader):\n","  print(batch_idx)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HQUyBAm0NDiF","outputId":"28803bad-4146-44fa-f7d2-b9fb1c5b5124"},"outputs":[{"name":"stdout","output_type":"stream","text":["fold0    0.798123\n","fold1    0.788890\n","fold2    0.807082\n","fold3    0.768318\n","oof      0.789483\n","dtype: float64\n"]}],"source":["scores = {f'fold{i}':j for i,j in enumerate(val_scores)}\n","scores['oof'] = np.corrcoef(oof_df['preds'], oof_df['score'])[0][1]\n","scores = pd.Series(scores)\n","print(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zmBZERwvNkCo"},"outputs":[],"source":["scores.to_csv(f'{CFG.out_path}/scores.csv')\n","oof_df.to_csv(f'{CFG.out_path}/oof_df.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1w5uFoGdqnkIBeoZRlOuJFwlnjjsNbRTK","timestamp":1654169874663},{"file_id":"1omHuxNQsXsp9AqAdUHsc_dt9KtP20yMP","timestamp":1654168824854},{"file_id":"1GP-aM4gbJLt_K4PjctRHRgU-p7AjxvC6","timestamp":1654167290824},{"file_id":"1PQsBMoKIQEQSVPuMOKwMFHmzcHbel78W","timestamp":1654165080313},{"file_id":"1DIjKU3ktcrs9RfESQSO4Xf2DNCAmSECb","timestamp":1653339588896},{"file_id":"1y0dkP43iXyooLt43fdk3ElIC6ndubdxd","timestamp":1653303566583},{"file_id":"1HgfHxBWVNXFQQ-VgAxmpLDpzfmcsO7U3","timestamp":1653263004769},{"file_id":"1Bi1AdwFa2IrEpkW_vMGZkOATD45BfjF5","timestamp":1653256357852},{"file_id":"1oY_J27W0Uv7QkVRwUZytT1mrvRgDXe4L","timestamp":1653203615891},{"file_id":"1cAftaWxxDtH2724hCJr8n0e_5Xhj8mPy","timestamp":1653125565109},{"file_id":"1ENNIPhZgUOS4XtGZ_7JWBH-731sVuHGM","timestamp":1653095567105},{"file_id":"1BlfrktS37Y0Gzb1HsRKJI3SrfqrlHIaL","timestamp":1653020571389},{"file_id":"1xoLboFCuSvLYtqoCVkPkypRFhm5-FQ93","timestamp":1653001405922}],"mount_file_id":"1Uet16e_JjpPbyK2arnGanjjlSSSDhiXH","authorship_tag":"ABX9TyN5flxIGh7VQFwBElCR3OYY"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}