{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2812,"status":"ok","timestamp":1655437080557,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"ODefLcHTuzkZ","outputId":"1d34c91e-b681-403d-ff16-706f59eb864c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Jun 17 03:37:57 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    42W / 400W |      0MiB / 40536MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12166,"status":"ok","timestamp":1655437145471,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"bfwZudNPMeuX","outputId":"b7891ae6-d1d3-4f4c-aa96-157fc48f2f04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.19.1\n","  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (1.21.6)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 71.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (21.3)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 72.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (2022.6.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (4.11.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.1) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.1) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.1) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 5.1 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["!pip install transformers==4.19.1\n","!pip install sentencepiece==0.1.96"]},{"cell_type":"markdown","metadata":{"id":"2AYyabEofCDW"},"source":["base: https://www.kaggle.com/code/ksork6s4/uspppm-bert-for-patents-baseline-train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-O7K0BPfBHO"},"outputs":[],"source":["# ----------------------------------------------\n","# Load Libraries\n","# ----------------------------------------------\n","import pathlib\n","from pathlib import Path\n","import sys\n","import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.nn import functional as F\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import BertForSequenceClassification, BertConfig, BertModel\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import tqdm\n","\n","import gc\n","gc.enable()"]},{"cell_type":"markdown","metadata":{"id":"lLCSxR_tfbtn"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nv0CdG49fTXR"},"outputs":[],"source":["class CFG:\n","    exp_id = 'exp127'\n","    input_path = 'input/'\n","    cpc_path = 'input/'\n","    model_path = 'anferico/bert-for-patents'\n","    out_base = 'output'\n","    out_path = f'{out_base}/{exp_id}'\n","    model_save_path = f'{out_path}/models'\n","    \n","    debug = False\n","    fold1_only = False\n","    upload_dataset = True\n","    debug_size = 100\n","    log_interval = 1822 # 未使用\n","    seed = 42\n","    max_len = 92\n","    learning_rate = 2e-5\n","    weight_decay = 0.01\n","    lr_decay = 0.98\n","    num_classes = 5\n","    num_fold = 4\n","    epochs = 5\n","    train_batch_size = 16\n","    valid_batch_size = 16\n","    gradient_accumulation_step = 1\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    if debug:\n","      epochs = 1\n","      upload_dataset = False\n","\n","    if fold1_only:\n","      upload_dataset = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2LXX-6iO5Re"},"outputs":[],"source":["!mkdir -p {CFG.out_path}\n","!mkdir -p {CFG.model_save_path}"]},{"cell_type":"markdown","metadata":{"id":"1M170jR7fcj8"},"source":["# Preproc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iK90exIjNouV"},"outputs":[],"source":["# ----------------------------------------------\n","# Set SEED\n","# ----------------------------------------------\n","# seed\n","SEED = CFG.seed\n","def set_seed(SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    \n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    \n","set_seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655420519163,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"yOJIHPpJikW3","outputId":"3c412a17-45a8-4ebc-9314-81f8857823af"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  \n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  "],"text/html":["\n","  <div id=\"df-34461ec1-f90c-428f-affc-681d88475d3f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34461ec1-f90c-428f-affc-681d88475d3f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-34461ec1-f90c-428f-affc-681d88475d3f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-34461ec1-f90c-428f-affc-681d88475d3f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["train_df = pd.read_csv(f\"{CFG.input_path}train.csv\")\n","# https://www.kaggle.com/code/gauravbrills/folds-dump-the-two-paths-fix\n","cpc_texts = torch.load(CFG.cpc_path+\"cpc_texts_fixed.pth\")\n","train_df['context_text'] = train_df['context'].map(cpc_texts)\n","display(train_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3048,"status":"ok","timestamp":1655420522205,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"OESlEphOfUcZ","outputId":"bb1900de-28f3-4e0f-9038-0f8aae2f1a71"},"outputs":[{"output_type":"stream","name":"stdout","text":["550 183\n","549 184\n","550 183\n","550 183\n"]}],"source":["!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train_df, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.num_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train_df = train_df.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1655420522205,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"sGikoiA9HfG2","outputId":"92aa847a-9eeb-4b6d-f174-dcc57b30232c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    9379\n","1    8860\n","2    8612\n","3    9622\n","Name: fold, dtype: int64"]},"metadata":{},"execution_count":14}],"source":["train_df['fold'].value_counts().sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655420522205,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"qskUdzrFG5uq","outputId":"384550ac-19b1-429f-dc13-433988a78072"},"outputs":[{"output_type":"stream","name":"stdout","text":["(36473, 7)\n"]},{"output_type":"execute_result","data":{"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  fold  \n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  "],"text/html":["\n","  <div id=\"df-0f7e3050-51d7-4d56-878a-57f3d5fe04b2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f7e3050-51d7-4d56-878a-57f3d5fe04b2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0f7e3050-51d7-4d56-878a-57f3d5fe04b2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0f7e3050-51d7-4d56-878a-57f3d5fe04b2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}],"source":["print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BTOQ441fgW6"},"outputs":[],"source":["train_df['input'] = train_df['anchor'] + '[SEP]' + train_df['target'] + '[SEP]' + train_df['context_text']"]},{"cell_type":"code","source":["train_df = pd.concat([train_df, pd.get_dummies(train_df['score'])], axis='columns')"],"metadata":{"id":"xClRI0Fa9_p9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df[[0.0,0.25,0.5,0.75,1.0]].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gM-fBBL1-iDw","executionInfo":{"status":"ok","timestamp":1655420522208,"user_tz":-540,"elapsed":19,"user":{"displayName":"堂込一智","userId":"12219727497971505625"}},"outputId":"b69d90f0-be87-4f91-c3e1-8ad4d01a6b07"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 1, 0, 0],\n","       [0, 0, 0, 1, 0],\n","       [0, 1, 0, 0, 0],\n","       ...,\n","       [0, 0, 1, 0, 0],\n","       [0, 0, 0, 1, 0],\n","       [0, 0, 1, 0, 0]], dtype=uint8)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655420522209,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"tjNzFNT8noYm","outputId":"19d4a4d3-8df2-47f4-b806-4e12f5c46de5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  fold  \\\n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","\n","                                               input  0.0  0.25  0.5  0.75  \\\n","0  abatement[SEP]abatement of pollution[SEP]HUMAN...    0     0    1     0   \n","1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...    0     0    0     1   \n","2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...    0     1    0     0   \n","3  abatement[SEP]eliminating process[SEP]HUMAN NE...    0     0    1     0   \n","4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...    1     0    0     0   \n","\n","   1.0  \n","0    0  \n","1    0  \n","2    0  \n","3    0  \n","4    0  "],"text/html":["\n","  <div id=\"df-6b5d06ca-d736-411b-beb0-c9067e070b66\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>fold</th>\n","      <th>input</th>\n","      <th>0.0</th>\n","      <th>0.25</th>\n","      <th>0.5</th>\n","      <th>0.75</th>\n","      <th>1.0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6b5d06ca-d736-411b-beb0-c9067e070b66')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6b5d06ca-d736-411b-beb0-c9067e070b66 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6b5d06ca-d736-411b-beb0-c9067e070b66');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"aAVnHp8Ofsso"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r1ADD0EJfgUj"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655420523456,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"h30ob5ihINOq","outputId":"2d2a4f8e-3546-4c6d-c6a1-2cc5ab323102"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\ntoken_len = train_df['input'].map(lambda x: tokenizer(x)['input_ids'].__len__())\\ndisplay(token_len.describe())\\ntoken_len.hist(bins=100)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}],"source":["# トークン長分布の確認\n","\"\"\"\n","token_len = train_df['input'].map(lambda x: tokenizer(x)['input_ids'].__len__())\n","display(token_len.describe())\n","token_len.hist(bins=100)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"n5qNQG7XfvtE"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5JyZ3RnfgRr"},"outputs":[],"source":["def prepare_input(tokenizer, text):\n","    inputs = tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=CFG.max_len,\n","                           padding=\"max_length\",\n","                           truncation=True,\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, df):\n","        self.inputs = df['input'].values\n","        #self.label = df['score'].values\n","        self.label = df[[0.0,0.25,0.5,0.75,1.0]].values\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, item):\n","        inputs = self.inputs[item]\n","        label = self.label[item]\n","        outputs = prepare_input(tokenizer, inputs)\n","        outputs['label'] = torch.tensor(label, dtype=torch.float32)\n","\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"ikO_UwLyf1KF"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTGp5AHE2e4o"},"outputs":[],"source":["# ----------------------------------------------\n","# Model\n","# ----------------------------------------------\n","class AttentionHead(nn.Module):\n","    def __init__(self, in_features, hidden_dim, num_targets):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.middle_features = hidden_dim\n","        self.W = nn.Linear(in_features, hidden_dim)\n","        self.V = nn.Linear(hidden_dim, 1)\n","        self.out_features = hidden_dim\n","\n","    def forward(self, features):\n","        att = torch.tanh(self.W(features))\n","        score = self.V(att)\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * features\n","        context_vector = torch.sum(context_vector, dim=1)\n","\n","        return context_vector\n","\n","class PPPMModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.config = AutoConfig.from_pretrained(CFG.model_path)\n","        self.config.update({\"output_hidden_states\": True})\n","        self.pre_model = AutoModel.from_pretrained(CFG.model_path, config=self.config)     \n","        self.dropout = nn.Dropout(self.config.hidden_dropout_prob)\n","        self.dropout1 = nn.Dropout(0.1)\n","        self.dropout2 = nn.Dropout(0.2)\n","        self.dropout3 = nn.Dropout(0.3)\n","        self.dropout4 = nn.Dropout(0.4)\n","        self.dropout5 = nn.Dropout(0.5)\n","        self.regressor = nn.Linear(self.config.hidden_size*4, CFG.num_classes)\n","    \n","    def forward(self, inputs):\n","        pre_out = self.pre_model(**inputs)\n","        #last_hidden_states = pre_out[0]\n","        head = torch.cat([pre_out[\"hidden_states\"][-1*i][:,0] for i in range(1, 4+1)], dim=1)  # concatenate  \n","        last_hidden_states = self.dropout(head)\n","        logits1 = self.regressor(self.dropout1(last_hidden_states))\n","        logits2 = self.regressor(self.dropout2(last_hidden_states))\n","        logits3 = self.regressor(self.dropout3(last_hidden_states))\n","        logits4 = self.regressor(self.dropout4(last_hidden_states))\n","        logits5 = self.regressor(self.dropout5(last_hidden_states))\n","        logits = (logits1 + logits2 + logits3 + logits4 + logits5) / 5\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfqjFdzk3yd3"},"outputs":[],"source":["# ----------------------------------------------\n","# func: valid, predict\n","# ----------------------------------------------\n","def predict(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), CFG.num_classes))\n","    idx = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          output = model(inputs)\n","          output = nn.Softmax(dim=1)(output)\n","          result[idx:idx + output.shape[0], :] = output.to('cpu')\n","          idx += output.shape[0]\n","            \n","    return result\n","\n","\n","def valid_func(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), CFG.num_classes))\n","    idx = 0\n","    loss_sum = 0\n","    bar = tqdm(dataloader, total=len(dataloader))\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(bar):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          label = data['label'].to(CFG.device)          \n","          output = model(inputs)\n","          output = nn.Softmax(dim=1)(output)\n","          result[idx:idx + output.shape[0], :] = output.to('cpu')\n","          idx += output.shape[0]\n","\n","          loss_sum += nn.CrossEntropyLoss(reduction='sum')(output, label).item()\n","            \n","    return loss_sum/(len(dataloader.dataset)), result.reshape((len(dataloader.dataset), CFG.num_classes))\n","\n","def label_to_score(label):\n","    return (label*[0,0.25,0.5,0.75,1.0]).sum(axis=1)\n","\n","def metric_pearson(predictions, labels):\n","    pred_score = label_to_score(predictions)\n","    label_score = label_to_score(labels)\n","    pearson = np.corrcoef(pred_score, label_score)[0][1]       \n","    return pearson"]},{"cell_type":"code","source":["\"\"\"preds = predict(model, valid_loader)\n","label_to_score(valid_loader.dataset.label)\n","metric_pearson(preds, valid_loader.dataset.label)\"\"\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"t2JSQz40B_UC","executionInfo":{"status":"ok","timestamp":1655420523457,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","userId":"12219727497971505625"}},"outputId":"e5548e9a-7c95-48a1-8c6d-4be6f251f132"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'preds = predict(model, valid_loader)\\nlabel_to_score(valid_loader.dataset.label)\\nmetric_pearson(preds, valid_loader.dataset.label)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0HFdCII38i_"},"outputs":[],"source":["# ----------------------------------------------\n","# func: train\n","# ----------------------------------------------\n","def train_fn(\n","    model,\n","    save_path,\n","    train_loader,\n","    val_loader,\n","    optimizer,\n","    scheduler=None,\n","    num_epochs=CFG.epochs\n","):\n","\n","    best_score = 0\n","    best_epoch = 0\n","    running_loss = 0.0\n","    dataset_size = 0\n","    log_interval = CFG.log_interval\n","    oof_preds = None\n","\n","    start = time.time()\n","\n","    for epoch in range(num_epochs):\n","        val_score = None\n","        model.train()\n","        bar = tqdm(train_loader, total=len(train_loader))\n","        for batch_idx, data in enumerate(bar):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          label = data['label'].to(CFG.device)\n","          batch_size = label.size(0)\n","\n","          output = model(inputs)\n","          loss = nn.CrossEntropyLoss()(output, label)\n","          loss = loss / CFG.gradient_accumulation_step\n","\n","          loss.backward()\n","\n","          if (batch_idx + 1) % CFG.gradient_accumulation_step == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            if scheduler:\n","                scheduler.step()\n","\n","          if CFG.debug == True:\n","            if (batch_idx > 0) & (batch_idx % CFG.debug_size == 0):\n","                break\n","\n","          running_loss += (loss.item() * batch_size)\n","          dataset_size += batch_size            \n","          total_loss = running_loss / dataset_size\n","          bar.set_postfix(Epoch=epoch, Loss=loss.item(), TotalLoss=total_loss, LR=optimizer.param_groups[0]['lr'])\n","\n","        val_start = time.time()\n","        val_score, predictions = valid_func(model, val_loader)\n","        pearson = metric_pearson(predictions, val_loader.dataset.label)\n","        print(f\"Epoch {epoch+1}, Step {batch_idx+1}, train_loss: {loss:0.5f}, val_loss: {val_score:0.5f}, pearson: {pearson:0.5f}\")\n","        if pearson > best_score:\n","            print(f\"Model Inproved: {best_score} ----> {pearson}\")\n","            best_score = pearson\n","            oof_preds = predictions\n","            torch.save(model.state_dict(), save_path)\n","        print(f\"validation elasped time: {time.time() - val_start: 0.3}\")\n","\n","    print(f\"total elasped time: {time.time() - start: 0.3}\")\n","    start = time.time()\n","\n","    return best_score, oof_preds\n","\n","# ----------------------------------------------\n","# create optimizer\n","# ----------------------------------------------\n","def create_optimizer(model):\n","    named_params = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optim_params = []\n","    for idx_, (name_, params_) in enumerate(named_params):\n","        weight_decay = 0 if name_ in no_decay else 0.01\n","        optim_params.append({'params':params_,\n","                            'weight_decay': weight_decay,\n","                            })\n","\n","    return AdamW(optim_params)\n","\n","\n","# https://www.ai-shift.co.jp/techblog/2145\n","def create_optimizer_grouped_parameters(model):\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": 1e-3,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, 'pre_model').embeddings] + list(getattr(model, 'pre_model').encoder.layer)\n","    layers.reverse()\n","    lr = CFG.learning_rate\n","    for layer in layers:\n","        lr *= CFG.lr_decay\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": CFG.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return AdamW(optimizer_grouped_parameters)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxz1VyLy6wkn","outputId":"3c15040e-ac29-45a4-8070-fdf2b3e119af","executionInfo":{"status":"ok","timestamp":1655424811887,"user_tz":-540,"elapsed":4288436,"user":{"displayName":"堂込一智","userId":"12219727497971505625"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["*** FOLD 1 / 4***\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","100%|██████████| 1693/1693 [03:11<00:00,  8.86it/s, Epoch=0, LR=0.000913, Loss=0.514, TotalLoss=0.95]\n","100%|██████████| 587/587 [00:17<00:00, 33.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Step 1693, train_loss: 0.51354, val_loss: 1.26599, pearson: 0.81584\n","Model Inproved: 0 ----> 0.8158388648094539\n","validation elasped time:  26.8\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1693/1693 [03:11<00:00,  8.85it/s, Epoch=1, LR=0.000665, Loss=0.462, TotalLoss=0.78]\n","100%|██████████| 587/587 [00:17<00:00, 34.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Step 1693, train_loss: 0.46205, val_loss: 1.22580, pearson: 0.82069\n","Model Inproved: 0.8158388648094539 ----> 0.8206906985176693\n","validation elasped time:  22.3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1693/1693 [03:11<00:00,  8.85it/s, Epoch=2, LR=0.000353, Loss=0.439, TotalLoss=0.649]\n","100%|██████████| 587/587 [00:17<00:00, 34.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Step 1693, train_loss: 0.43869, val_loss: 1.20781, pearson: 0.82705\n","Model Inproved: 0.8206906985176693 ----> 0.8270490402074299\n","validation elasped time:  22.7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1693/1693 [03:11<00:00,  8.85it/s, Epoch=3, LR=9.77e-5, Loss=0.224, TotalLoss=0.542]\n","100%|██████████| 587/587 [00:16<00:00, 34.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Step 1693, train_loss: 0.22402, val_loss: 1.20181, pearson: 0.82041\n","validation elasped time:  16.9\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1693/1693 [03:11<00:00,  8.86it/s, Epoch=4, LR=0, Loss=0.0348, TotalLoss=0.459]\n","100%|██████████| 587/587 [00:17<00:00, 34.10it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Step 1693, train_loss: 0.03481, val_loss: 1.19977, pearson: 0.81495\n","validation elasped time:  17.2\n","total elasped time:  1.06e+03\n","[0.8270490402074299]\n","Mean: 0.8270490402074299\n","*** FOLD 2 / 4***\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1725/1725 [03:15<00:00,  8.82it/s, Epoch=0, LR=0.000913, Loss=0.957, TotalLoss=0.931]\n","100%|██████████| 554/554 [00:16<00:00, 34.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Step 1725, train_loss: 0.95675, val_loss: 1.25519, pearson: 0.80728\n","Model Inproved: 0 ----> 0.807275655232252\n","validation elasped time:  20.3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1725/1725 [03:15<00:00,  8.83it/s, Epoch=1, LR=0.000665, Loss=0.715, TotalLoss=0.761]\n","100%|██████████| 554/554 [00:16<00:00, 34.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Step 1725, train_loss: 0.71482, val_loss: 1.23091, pearson: 0.81561\n","Model Inproved: 0.807275655232252 ----> 0.8156091596026211\n","validation elasped time:  20.3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1725/1725 [03:15<00:00,  8.82it/s, Epoch=2, LR=0.000353, Loss=0.437, TotalLoss=0.63]\n","100%|██████████| 554/554 [00:16<00:00, 34.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Step 1725, train_loss: 0.43695, val_loss: 1.22210, pearson: 0.80943\n","validation elasped time:  16.2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1725/1725 [03:15<00:00,  8.82it/s, Epoch=3, LR=9.77e-5, Loss=0.0385, TotalLoss=0.523]\n","100%|██████████| 554/554 [00:16<00:00, 33.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Step 1725, train_loss: 0.03846, val_loss: 1.21305, pearson: 0.80811\n","validation elasped time:  16.4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1725/1725 [03:16<00:00,  8.79it/s, Epoch=4, LR=0, Loss=0.00685, TotalLoss=0.441]\n","100%|██████████| 554/554 [00:16<00:00, 34.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Step 1725, train_loss: 0.00685, val_loss: 1.20863, pearson: 0.80544\n","validation elasped time:  16.2\n","total elasped time:  1.07e+03\n","[0.8270490402074299, 0.8156091596026211]\n","Mean: 0.8213290999050256\n","*** FOLD 3 / 4***\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1741/1741 [03:18<00:00,  8.78it/s, Epoch=0, LR=0.000913, Loss=1.06, TotalLoss=0.949]\n","100%|██████████| 539/539 [00:15<00:00, 34.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Step 1741, train_loss: 1.06450, val_loss: 1.26002, pearson: 0.81140\n","Model Inproved: 0 ----> 0.8114031208062441\n","validation elasped time:  19.7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1741/1741 [03:17<00:00,  8.81it/s, Epoch=1, LR=0.000665, Loss=0.745, TotalLoss=0.778]\n","100%|██████████| 539/539 [00:15<00:00, 34.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Step 1741, train_loss: 0.74500, val_loss: 1.22304, pearson: 0.82414\n","Model Inproved: 0.8114031208062441 ----> 0.8241441670641664\n","validation elasped time:  19.8\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1741/1741 [03:17<00:00,  8.83it/s, Epoch=2, LR=0.000352, Loss=0.208, TotalLoss=0.646]\n","100%|██████████| 539/539 [00:16<00:00, 33.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Step 1741, train_loss: 0.20812, val_loss: 1.20105, pearson: 0.83364\n","Model Inproved: 0.8241441670641664 ----> 0.8336366645518293\n","validation elasped time:  20.2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1741/1741 [03:17<00:00,  8.81it/s, Epoch=3, LR=9.76e-5, Loss=0.102, TotalLoss=0.537]\n","100%|██████████| 539/539 [00:15<00:00, 33.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Step 1741, train_loss: 0.10192, val_loss: 1.19098, pearson: 0.82825\n","validation elasped time:  15.9\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1741/1741 [03:17<00:00,  8.80it/s, Epoch=4, LR=0, Loss=0.0413, TotalLoss=0.454]\n","100%|██████████| 539/539 [00:16<00:00, 33.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Step 1741, train_loss: 0.04131, val_loss: 1.19067, pearson: 0.82529\n","validation elasped time:  16.1\n","total elasped time:  1.08e+03\n","[0.8270490402074299, 0.8156091596026211, 0.8336366645518293]\n","Mean: 0.8254316214539602\n","*** FOLD 4 / 4***\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at anferico/bert-for-patents were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1678/1678 [03:10<00:00,  8.79it/s, Epoch=0, LR=0.000913, Loss=1.2, TotalLoss=0.962]\n","100%|██████████| 602/602 [00:17<00:00, 34.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1, Step 1678, train_loss: 1.19902, val_loss: 1.30165, pearson: 0.75854\n","Model Inproved: 0 ----> 0.7585390510313522\n","validation elasped time:  21.7\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1678/1678 [03:10<00:00,  8.83it/s, Epoch=1, LR=0.000665, Loss=0.708, TotalLoss=0.795]\n","100%|██████████| 602/602 [00:17<00:00, 34.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2, Step 1678, train_loss: 0.70772, val_loss: 1.25291, pearson: 0.79298\n","Model Inproved: 0.7585390510313522 ----> 0.7929836125241606\n","validation elasped time:  21.5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1678/1678 [03:10<00:00,  8.83it/s, Epoch=2, LR=0.000353, Loss=0.462, TotalLoss=0.666]\n","100%|██████████| 602/602 [00:17<00:00, 34.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3, Step 1678, train_loss: 0.46177, val_loss: 1.23442, pearson: 0.79621\n","Model Inproved: 0.7929836125241606 ----> 0.7962142730579702\n","validation elasped time:  21.4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1678/1678 [03:10<00:00,  8.82it/s, Epoch=3, LR=9.77e-5, Loss=0.482, TotalLoss=0.557]\n","100%|██████████| 602/602 [00:17<00:00, 34.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4, Step 1678, train_loss: 0.48199, val_loss: 1.21801, pearson: 0.79521\n","validation elasped time:  17.6\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1678/1678 [03:09<00:00,  8.83it/s, Epoch=4, LR=0, Loss=0.0306, TotalLoss=0.472]\n","100%|██████████| 602/602 [00:17<00:00, 34.62it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5, Step 1678, train_loss: 0.03063, val_loss: 1.21668, pearson: 0.79262\n","validation elasped time:  17.4\n","total elasped time:  1.05e+03\n","[0.8270490402074299, 0.8156091596026211, 0.8336366645518293, 0.7962142730579702]\n","Mean: 0.8181272843549627\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# ----------------------------------------------\n","# Main Loop\n","# ----------------------------------------------\n","val_scores = []\n","oof_df = pd.DataFrame()\n","\n","for fold in range(CFG.num_fold): \n","    print(f\"*** FOLD {fold+1} / {CFG.num_fold}***\")\n","\n","    save_path = f\"{CFG.model_save_path}/model_{fold+1}.pth\"\n","\n","    train_data = train_df[train_df['fold'] != fold]\n","    valid_data = train_df[train_df['fold'] == fold]\n","    train_set = TrainDataset(train_data)\n","    valid_set = TrainDataset(valid_data)\n","\n","    train_loader = DataLoader(train_set,\n","                            batch_size=CFG.train_batch_size,\n","                            shuffle=True,\n","                            drop_last=True,\n","                            num_workers=2,\n","                            pin_memory=True)\n","    valid_loader = DataLoader(valid_set,\n","                            batch_size=CFG.valid_batch_size,\n","                            shuffle=False,\n","                            drop_last=False,\n","                            num_workers=2,\n","                            pin_memory=True)\n","\n","    model = PPPMModel().to(CFG.device)\n","    optimizer = create_optimizer_grouped_parameters(model)\n","    #optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)\n","    scheduler = get_cosine_schedule_with_warmup(\n","        optimizer,\n","        num_training_steps=CFG.epochs*len(train_loader),\n","        num_warmup_steps=100\n","    )\n","\n","    val_score, val_preds = train_fn(model, save_path, train_loader, valid_loader, optimizer, scheduler=scheduler)\n","    val_scores.append(val_score)\n","    val_preds = label_to_score(val_preds)\n","    valid_data['preds'] = val_preds\n","    oof_df = pd.concat([oof_df, valid_data])\n","\n","    del model\n","    torch.cuda.empty_cache()\n","\n","    print(val_scores)\n","    print(\"Mean:\", np.array(val_scores).mean())\n","    if CFG.fold1_only == True:\n","        if fold == 0:\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nz0KfPOAXBbi","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1655424812641,"user_tz":-540,"elapsed":765,"user":{"displayName":"堂込一智","userId":"12219727497971505625"}},"outputId":"7661cc64-b4b5-4315-e232-0341658715f4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'for batch_idx, data in enumerate(valid_loader):\\n  print(batch_idx)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}],"source":["\"\"\"for batch_idx, data in enumerate(valid_loader):\n","  print(batch_idx)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HQUyBAm0NDiF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655424812641,"user_tz":-540,"elapsed":7,"user":{"displayName":"堂込一智","userId":"12219727497971505625"}},"outputId":"29f0b803-0f90-4df1-a043-04d89401cfa5"},"outputs":[{"output_type":"stream","name":"stdout","text":["fold0    0.827049\n","fold1    0.815609\n","fold2    0.833637\n","fold3    0.796214\n","oof      0.817393\n","dtype: float64\n"]}],"source":["scores = {f'fold{i}':j for i,j in enumerate(val_scores)}\n","scores['oof'] = np.corrcoef(oof_df['preds'], oof_df['score'])[0][1]\n","scores = pd.Series(scores)\n","print(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zmBZERwvNkCo"},"outputs":[],"source":["scores.to_csv(f'{CFG.out_path}/scores.csv')\n","oof_df.to_csv(f'{CFG.out_path}/oof_df.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMQZUj7z8dea"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1nm9Mh83tpVkRtgzIW70V3KYDeQuT8pHY","timestamp":1655115771299},{"file_id":"1w5uFoGdqnkIBeoZRlOuJFwlnjjsNbRTK","timestamp":1654169874663},{"file_id":"1omHuxNQsXsp9AqAdUHsc_dt9KtP20yMP","timestamp":1654168824854},{"file_id":"1GP-aM4gbJLt_K4PjctRHRgU-p7AjxvC6","timestamp":1654167290824},{"file_id":"1PQsBMoKIQEQSVPuMOKwMFHmzcHbel78W","timestamp":1654165080313},{"file_id":"1DIjKU3ktcrs9RfESQSO4Xf2DNCAmSECb","timestamp":1653339588896},{"file_id":"1y0dkP43iXyooLt43fdk3ElIC6ndubdxd","timestamp":1653303566583},{"file_id":"1HgfHxBWVNXFQQ-VgAxmpLDpzfmcsO7U3","timestamp":1653263004769},{"file_id":"1Bi1AdwFa2IrEpkW_vMGZkOATD45BfjF5","timestamp":1653256357852},{"file_id":"1oY_J27W0Uv7QkVRwUZytT1mrvRgDXe4L","timestamp":1653203615891},{"file_id":"1cAftaWxxDtH2724hCJr8n0e_5Xhj8mPy","timestamp":1653125565109},{"file_id":"1ENNIPhZgUOS4XtGZ_7JWBH-731sVuHGM","timestamp":1653095567105},{"file_id":"1BlfrktS37Y0Gzb1HsRKJI3SrfqrlHIaL","timestamp":1653020571389},{"file_id":"1xoLboFCuSvLYtqoCVkPkypRFhm5-FQ93","timestamp":1653001405922}],"mount_file_id":"1Uet16e_JjpPbyK2arnGanjjlSSSDhiXH","authorship_tag":"ABX9TyMmFJ2RxFSAyC0QbIXwzHl2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}