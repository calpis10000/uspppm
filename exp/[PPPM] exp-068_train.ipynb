{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654292000316,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"ODefLcHTuzkZ","outputId":"9404171f-2fc4-428a-8c30-d7fab47e9253"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fri Jun  3 21:33:19 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13115,"status":"ok","timestamp":1654292044072,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"bfwZudNPMeuX","outputId":"b53866db-9fc5-4e3b-d9e1-75b924e68ca8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers==4.19.1\n","  Downloading transformers-4.19.1-py3-none-any.whl (4.2 MB)\n","\u001b[K     |████████████████████████████████| 4.2 MB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 49.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (4.11.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (3.7.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.1) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 6.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 74.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.1) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.1) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.1) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.1) (1.24.3)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece==0.1.96\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 4.2 MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.96\n"]}],"source":["!pip install transformers==4.19.1\n","!pip install sentencepiece==0.1.96"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p-O7K0BPfBHO"},"outputs":[],"source":["# ----------------------------------------------\n","# Load Libraries\n","# ----------------------------------------------\n","import pathlib\n","from pathlib import Path\n","import sys\n","import os\n","import math\n","import random\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n","from transformers import AdamW\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import BertForSequenceClassification, BertConfig, BertModel\n","from transformers import get_cosine_schedule_with_warmup\n","\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.model_selection import train_test_split\n","\n","from tqdm import tqdm\n","\n","import gc\n","gc.enable()"]},{"cell_type":"markdown","metadata":{"id":"lLCSxR_tfbtn"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nv0CdG49fTXR"},"outputs":[],"source":["class CFG:\n","    exp_id = 'exp068'\n","    input_path = 'input/'\n","    cpc_path = 'input/'\n","    model_path = 'microsoft/deberta-v3-base'\n","    out_base = '/content/drive/MyDrive/Colab_Files/kaggle/pppm/output'\n","    out_path = f'{out_base}/{exp_id}'\n","    scores_path = f'{out_path}/scores'\n","    \n","    debug = False\n","    fold1_only = False\n","    upload_dataset = True\n","    debug_size = 100\n","    log_interval = 1822 # 未使用\n","    seed = 42\n","    max_len = 92\n","    learning_rate = 2e-5\n","    weight_decay = 0.01\n","    lr_decay = 0.98\n","    num_classes = 1\n","    num_fold = 4\n","    epochs = 5\n","    train_batch_size = 16\n","    valid_batch_size = 16\n","    gradient_accumulation_step = 1\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","    if debug:\n","      epochs = 1\n","      upload_dataset = False\n","\n","    if fold1_only:\n","      upload_dataset = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2LXX-6iO5Re"},"outputs":[],"source":["!mkdir -p {CFG.out_path}\n","!mkdir -p {CFG.scores_path}"]},{"cell_type":"markdown","metadata":{"id":"1M170jR7fcj8"},"source":["# Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iK90exIjNouV"},"outputs":[],"source":["# ----------------------------------------------\n","# Set SEED\n","# ----------------------------------------------\n","# seed\n","SEED = CFG.seed\n","def set_seed(SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    os.environ['PYTHONHASHSEED'] = str(SEED)\n","    \n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.cuda.manual_seed_all(SEED)\n","    torch.backends.cudnn.deterministic = True\n","    \n","set_seed(SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2367,"status":"ok","timestamp":1654292052289,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"yOJIHPpJikW3","outputId":"13cf34e9-1f56-4646-af8f-d435b04fa5a9"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-013217a9-4be6-4626-b873-b18299b6ab67\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-013217a9-4be6-4626-b873-b18299b6ab67')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-013217a9-4be6-4626-b873-b18299b6ab67 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-013217a9-4be6-4626-b873-b18299b6ab67');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  \n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  "]},"metadata":{},"output_type":"display_data"}],"source":["train_df = pd.read_csv(f\"{CFG.input_path}train.csv\")\n","# https://www.kaggle.com/code/gauravbrills/folds-dump-the-two-paths-fix\n","cpc_texts = torch.load(CFG.cpc_path+\"cpc_texts_fixed.pth\")\n","train_df['context_text'] = train_df['context'].map(cpc_texts)\n","display(train_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5260,"status":"ok","timestamp":1654292057542,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"OESlEphOfUcZ","outputId":"9e12bf6c-d15a-4e24-fc08-4fe7a4537e94"},"outputs":[{"name":"stdout","output_type":"stream","text":["550 183\n","549 184\n","550 183\n","550 183\n"]}],"source":["!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train_df, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.num_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train_df = train_df.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1654292057542,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"sGikoiA9HfG2","outputId":"78ac7e28-ae96-42cf-c9e3-54f0de90917e"},"outputs":[{"data":{"text/plain":["0    9379\n","1    8860\n","2    8612\n","3    9622\n","Name: fold, dtype: int64"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["train_df['fold'].value_counts().sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1654292057543,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"qskUdzrFG5uq","outputId":"20725f1b-51a4-4ef4-95f4-6b79ba0827a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["(36473, 7)\n"]},{"data":{"text/html":["\n","  <div id=\"df-7c58ba89-a632-40d3-82d5-f10b44f232ec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c58ba89-a632-40d3-82d5-f10b44f232ec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7c58ba89-a632-40d3-82d5-f10b44f232ec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7c58ba89-a632-40d3-82d5-f10b44f232ec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  fold  \n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["print(train_df.shape)\n","train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1654292057543,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"npXkzRTkDmL4","outputId":"3e4f0828-fb03-42dd-c313-bff9d7e036e0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"train_df['con_grp'] = train_df['context'].map(lambda x: x[:1])\\ntrain_df.groupby('fold')['con_grp'].value_counts().sort_index()\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"train_df['con_grp'] = train_df['context'].map(lambda x: x[:1])\n","train_df.groupby('fold')['con_grp'].value_counts().sort_index()\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9BTOQ441fgW6"},"outputs":[],"source":["train_df['input'] = train_df['anchor'] + '[SEP]' + train_df['target'] + '[SEP]' + train_df['context_text']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1654292057544,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"tjNzFNT8noYm","outputId":"747ee7e7-0398-44c0-fe13-a4f4c18711b8"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-b9e17d51-fdcf-4385-b154-b6ab709228a4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>fold</th>\n","      <th>input</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]abatement of pollution[SEP]HUMAN...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]act of abating[SEP]HUMAN NECESSI...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]active catalyst[SEP]HUMAN NECESS...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]eliminating process[SEP]HUMAN NE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>0</td>\n","      <td>abatement[SEP]forest region[SEP]HUMAN NECESSIT...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9e17d51-fdcf-4385-b154-b6ab709228a4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b9e17d51-fdcf-4385-b154-b6ab709228a4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b9e17d51-fdcf-4385-b154-b6ab709228a4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score  \\\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50   \n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75   \n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25   \n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50   \n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00   \n","\n","                                        context_text  fold  \\\n","0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","1  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","2  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","3  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","4  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     0   \n","\n","                                               input  \n","0  abatement[SEP]abatement of pollution[SEP]HUMAN...  \n","1  abatement[SEP]act of abating[SEP]HUMAN NECESSI...  \n","2  abatement[SEP]active catalyst[SEP]HUMAN NECESS...  \n","3  abatement[SEP]eliminating process[SEP]HUMAN NE...  \n","4  abatement[SEP]forest region[SEP]HUMAN NECESSIT...  "]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{"id":"aAVnHp8Ofsso"},"source":["# Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204,"referenced_widgets":["225116e42e2942799492783f3b2603e4","d6f9b972d61d495d908962da340e2a61","559924f78faf4f05a2bec5732e7a06db","1f63c90aa0df459fa0890a7937f0e585","ad4ea4ea59b9461e933f6f74a4e490de","b9f21bb4d6db4c54ba0a007a387c37b0","3b19e5be0a5d49bc957a87de816e7fb5","02b773f093af4dde9ee495f4ed1bce8c","85f292285ac041698da5c41d5eaa65a9","7cd8788b006543d3b2206d56bc88f50b","981f6b3affae46eb9cb280d29b599433","be1e4f6a5db04a6ead8af8e63e080b8c","895ff65933324d7799fe5f86b8bdc36d","5d2b97d56e704003ab803590dfd240ff","d53f9c72ea70448b9863f220005eb19b","a34ebc39cacc4fd09864b63404277d13","4cf9db6cafbc48e7a0556e1df2df058c","ff350ef3ec134427bb7c2a4ef1acc65b","5d937aba9ee0408c83c381a7cf62d897","151e6ef3434a4c0d860c1a01413936a9","6ce1dbac9dff4214919611f3ddd899db","ec1820ca43d3401fa27524ca34e0425d","9fe1769a5fdf42adb2d63fd50d7c9689","7f401f6e1f1e4db8b550db2b40edf0db","f9ea242396e94f0fbac538f37870aaed","f8b7922bb6d24e07ab2aeb9e46f3af47","1075a3ae347d41399d7e0d2f30e632fa","97df9c4d69694a10ae1e71df55a7d13e","d2f6cea6f56a40abb824d127323a9252","765322cb909949ed8a0ca577252f8ae6","d8eddf3fba024b5698b7b163d94299f6","1eeeec1a8ef540b684d2b0536ec8b96b","c84d82dea3b945aab7d63102ec400261"]},"executionInfo":{"elapsed":9546,"status":"ok","timestamp":1654292067080,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"r1ADD0EJfgUj","outputId":"9ba48964-cfb6-4f8b-92b9-ee7fb1abdc13"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"225116e42e2942799492783f3b2603e4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be1e4f6a5db04a6ead8af8e63e080b8c","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/579 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fe1769a5fdf42adb2d63fd50d7c9689","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","/usr/local/lib/python3.7/dist-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(CFG.model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1654292067080,"user":{"displayName":"堂込一智","userId":"12219727497971505625"},"user_tz":-540},"id":"h30ob5ihINOq","outputId":"c09dc46e-be88-421e-ec4c-862ebe2b445e"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"\\ntoken_len = train_df['input'].map(lambda x: tokenizer(x)['input_ids'].__len__())\\ndisplay(token_len.describe())\\ntoken_len.hist(bins=100)\\n\""]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# トークン長分布の確認\n","\"\"\"\n","token_len = train_df['input'].map(lambda x: tokenizer(x)['input_ids'].__len__())\n","display(token_len.describe())\n","token_len.hist(bins=100)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"n5qNQG7XfvtE"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r5JyZ3RnfgRr"},"outputs":[],"source":["def prepare_input(tokenizer, text):\n","    inputs = tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=CFG.max_len,\n","                           padding=\"max_length\",\n","                           truncation=True,\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, df):\n","        self.inputs = df['input'].values\n","        self.label = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, item):\n","        inputs = self.inputs[item]\n","        label = self.label[item]\n","        outputs = prepare_input(tokenizer, inputs)\n","        outputs['label'] = torch.tensor(label, dtype=torch.float32)\n","\n","        return outputs"]},{"cell_type":"markdown","metadata":{"id":"ikO_UwLyf1KF"},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nTGp5AHE2e4o"},"outputs":[],"source":["# ----------------------------------------------\n","# Model\n","# ----------------------------------------------\n","class AttentionHead(nn.Module):\n","    def __init__(self, in_features, hidden_dim, num_targets):\n","        super().__init__()\n","        self.in_features = in_features\n","        self.middle_features = hidden_dim\n","        self.W = nn.Linear(in_features, hidden_dim)\n","        self.V = nn.Linear(hidden_dim, 1)\n","        self.out_features = hidden_dim\n","\n","    def forward(self, features):\n","        att = torch.tanh(self.W(features))\n","        score = self.V(att)\n","        attention_weights = torch.softmax(score, dim=1)\n","        context_vector = attention_weights * features\n","        context_vector = torch.sum(context_vector, dim=1)\n","\n","        return context_vector\n","\n","class PPPMModel(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.num_reinit_layers = 6\n","        self.config = AutoConfig.from_pretrained(CFG.model_path)\n","        self.config.attention_probs_dropout_prob = 0.0\n","        self.config.hidden_dropout_prob = 0.0\n","        self.pre_model = AutoModel.from_pretrained(CFG.model_path, config=self.config)\n","        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size,1)\n","        #self.dropout = nn.Dropout(0.3)\n","        self.regressor = nn.Linear(self.config.hidden_size, CFG.num_classes)\n","        #self.initialize()\n","    \n","    def forward(self, inputs):\n","        pre_out = self.pre_model(**inputs)\n","        x = pre_out[0]\n","        x = self.head(x)\n","        x = self.regressor(x)\n","        return x\n","  \n","    def initialize(self):\n","      for i in range(self.num_reinit_layers):\n","          self.pre_model.encoder.layer[-(1 + i)].apply(self._init_weight)\n","\n","    def _init_weight(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.pre_model.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfqjFdzk3yd3"},"outputs":[],"source":["# ----------------------------------------------\n","# func: valid, predict\n","# ----------------------------------------------\n","def predict(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), CFG.num_classes))\n","    idx = 0\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(dataloader):\n","          inputs = {}\n","          for k, v in data.items():\n","            inputs[k] = v.to(CFG.device)            \n","          output = model(inputs)\n","          result[idx:idx + output.shape[0], :] = output.to('cpu')\n","          idx += output.shape[0]\n","            \n","    return result\n","\n","\n","def valid_mse(model, dataloader):\n","    model.eval()\n","    result = np.zeros((len(dataloader.dataset), CFG.num_classes))\n","    idx = 0\n","    mse_sum = 0\n","    bar = tqdm(dataloader, total=len(dataloader))\n","    \n","    with torch.no_grad():\n","        for batch_idx, data in enumerate(bar):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          label = data['label'].to(CFG.device)          \n","          output = model(inputs)\n","          result[idx:idx + output.shape[0], :] = output.to('cpu')\n","          idx += output.shape[0]\n","\n","          mse_sum += nn.MSELoss(reduction='sum')(output.flatten(), label).item()\n","            \n","    return mse_sum/(len(dataloader.dataset)), result.reshape(len(result))\n","\n","\n","def metric_pearson(predictions, labels):\n","    pearson = np.corrcoef(predictions, labels)[0][1]       \n","    return pearson"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y0HFdCII38i_"},"outputs":[],"source":["# ----------------------------------------------\n","# func: train\n","# ----------------------------------------------\n","def train_fn(\n","    model,\n","    save_path,\n","    train_loader,\n","    val_loader,\n","    optimizer,\n","    scheduler=None,\n","    num_epochs=CFG.epochs\n","):\n","\n","    best_score = 0\n","    best_epoch = 0\n","    running_loss = 0.0\n","    dataset_size = 0\n","    log_interval = CFG.log_interval\n","    oof_preds = None\n","\n","    start = time.time()\n","\n","    for epoch in range(num_epochs):\n","        val_score = None\n","        model.train()\n","        bar = tqdm(train_loader, total=len(train_loader))\n","        for batch_idx, data in enumerate(bar):\n","          inputs = {}\n","          for k, v in data.items():\n","            if k != 'label':\n","              inputs[k] = v.to(CFG.device)            \n","          label = data['label'].to(CFG.device)\n","          batch_size = label.size(0)\n","\n","          output = model(inputs)\n","          loss = nn.MSELoss()(output.flatten(), label)\n","          loss = loss / CFG.gradient_accumulation_step\n","\n","          loss.backward()\n","\n","          if (batch_idx + 1) % CFG.gradient_accumulation_step == 0:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","            if scheduler:\n","                scheduler.step()\n","\n","          if CFG.debug == True:\n","            if (batch_idx > 0) & (batch_idx % CFG.debug_size == 0):\n","                break\n","\n","          running_loss += (loss.item() * batch_size)\n","          dataset_size += batch_size            \n","          total_loss = running_loss / dataset_size\n","          bar.set_postfix(Epoch=epoch, Loss=loss.item(), TotalLoss=total_loss, LR=optimizer.param_groups[0]['lr'])\n","\n","        val_start = time.time()\n","        val_score, predictions = valid_mse(model, val_loader)\n","        pearson = metric_pearson(predictions, val_loader.dataset.label)\n","        print(f\"Epoch {epoch+1}, Step {batch_idx+1}, train_loss: {loss:0.5f}, val_loss: {val_score:0.5f}, pearson: {pearson:0.5f}\")\n","        if pearson > best_score:\n","            print(f\"Model Inproved: {best_score} ----> {pearson}\")\n","            best_score = pearson\n","            oof_preds = predictions\n","            torch.save(model.state_dict(), save_path)\n","        print(f\"validation elasped time: {time.time() - val_start: 0.3}\")\n","\n","    print(f\"total elasped time: {time.time() - start: 0.3}\")\n","    start = time.time()\n","\n","    return best_score, oof_preds\n","\n","# ----------------------------------------------\n","# create optimizer\n","# ----------------------------------------------\n","def create_optimizer(model):\n","    named_params = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optim_params = []\n","    for idx_, (name_, params_) in enumerate(named_params):\n","        weight_decay = 0 if name_ in no_decay else 0.01\n","        optim_params.append({'params':params_,\n","                            'weight_decay': weight_decay,\n","                            })\n","\n","    return AdamW(optim_params)\n","\n","\n","# https://www.ai-shift.co.jp/techblog/2145\n","def create_optimizer_grouped_parameters(model):\n","    no_decay = [\"bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters()\n","                       if 'lstm' in n\n","                       or 'cnn' in n\n","                       or 'regressor' in n],\n","            \"weight_decay\": 0.0,\n","            \"lr\": 1e-3,\n","        },\n","    ]\n","    num_layers = model.config.num_hidden_layers\n","    layers = [getattr(model, 'pre_model').embeddings] + list(getattr(model, 'pre_model').encoder.layer)\n","    layers.reverse()\n","    lr = CFG.learning_rate\n","    for layer in layers:\n","        lr *= CFG.lr_decay\n","        optimizer_grouped_parameters += [\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if not any(nd in n for nd in no_decay)],\n","                \"weight_decay\": CFG.weight_decay,\n","                \"lr\": lr,\n","            },\n","            {\n","                \"params\": [p for n, p in layer.named_parameters() if any(nd in n for nd in no_decay)],\n","                \"weight_decay\": 0.0,\n","                \"lr\": lr,\n","            },\n","        ]\n","    return AdamW(optimizer_grouped_parameters)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["220c5226b678407e914f926728e14ab6","72d1289391b84e60913ed3d225daf2a3","bfe499f531b743539ae901a19804048c","294d517e75be4383ab059c4ee85a671f","e06fb744a7284ab0a1a5cf14cee6a1d6","923d1c215c124da295cdd1b2bf67ec52","1b57025a5322414f9af096844f5dfbbc","6e5ef74bf7c74a06896073515f81476f","adab36b6656447ccb2d2b076caf63f60","9b0ff85cbdb14cd68ddb083e1dc1874c","fbe07cedba3a44caa3e2227af83f0294"]},"id":"gxz1VyLy6wkn","outputId":"a246c2fb-53d5-488a-ad74-95020cb208a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["*** FOLD 1 / 4***\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"220c5226b678407e914f926728e14ab6","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/354M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","100%|██████████| 1693/1693 [06:17<00:00,  4.49it/s, Epoch=0, LR=0.000913, Loss=0.0343, TotalLoss=0.0373]\n","100%|██████████| 587/587 [00:38<00:00, 15.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1693, train_loss: 0.03433, val_loss: 0.02833, pearson: 0.81365\n","Model Inproved: 0 ----> 0.813646228333363\n","validation elasped time:  41.7\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [06:16<00:00,  4.50it/s, Epoch=1, LR=0.000665, Loss=0.00561, TotalLoss=0.0268]\n","100%|██████████| 587/587 [00:38<00:00, 15.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1693, train_loss: 0.00561, val_loss: 0.02590, pearson: 0.81245\n","validation elasped time:  38.9\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [06:16<00:00,  4.50it/s, Epoch=2, LR=0.000353, Loss=0.0103, TotalLoss=0.0211]\n","100%|██████████| 587/587 [00:38<00:00, 15.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1693, train_loss: 0.01028, val_loss: 0.02280, pearson: 0.81547\n","Model Inproved: 0.813646228333363 ----> 0.8154666896091781\n","validation elasped time:  41.8\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [06:18<00:00,  4.47it/s, Epoch=3, LR=9.77e-5, Loss=0.00646, TotalLoss=0.0172]\n","100%|██████████| 587/587 [00:38<00:00, 15.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1693, train_loss: 0.00646, val_loss: 0.02361, pearson: 0.81160\n","validation elasped time:  38.6\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1693/1693 [06:18<00:00,  4.47it/s, Epoch=4, LR=0, Loss=0.00473, TotalLoss=0.0145]\n","100%|██████████| 587/587 [00:38<00:00, 15.19it/s]\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1693, train_loss: 0.00473, val_loss: 0.02387, pearson: 0.81026\n","validation elasped time:  38.7\n","total elasped time:  2.09e+03\n","[0.8154666896091781]\n","Mean: 0.8154666896091781\n","*** FOLD 2 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1725/1725 [06:25<00:00,  4.48it/s, Epoch=0, LR=0.000913, Loss=0.0234, TotalLoss=0.0318]\n","100%|██████████| 554/554 [00:36<00:00, 15.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1725, train_loss: 0.02341, val_loss: 0.02600, pearson: 0.79532\n","Model Inproved: 0 ----> 0.7953198452559671\n","validation elasped time:  39.9\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [06:26<00:00,  4.46it/s, Epoch=1, LR=0.000665, Loss=0.00729, TotalLoss=0.0235]\n","100%|██████████| 554/554 [00:36<00:00, 15.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1725, train_loss: 0.00729, val_loss: 0.02590, pearson: 0.80080\n","Model Inproved: 0.7953198452559671 ----> 0.8007960818600333\n","validation elasped time:  39.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [06:26<00:00,  4.47it/s, Epoch=2, LR=0.000353, Loss=0.00791, TotalLoss=0.0186]\n","100%|██████████| 554/554 [00:36<00:00, 15.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1725, train_loss: 0.00791, val_loss: 0.02368, pearson: 0.80846\n","Model Inproved: 0.8007960818600333 ----> 0.808456609315501\n","validation elasped time:  39.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [06:26<00:00,  4.46it/s, Epoch=3, LR=9.77e-5, Loss=0.00577, TotalLoss=0.0152]\n","100%|██████████| 554/554 [00:36<00:00, 15.18it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1725, train_loss: 0.00577, val_loss: 0.02451, pearson: 0.80254\n","validation elasped time:  36.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1725/1725 [06:25<00:00,  4.47it/s, Epoch=4, LR=0, Loss=0.00154, TotalLoss=0.0127]\n","100%|██████████| 554/554 [00:36<00:00, 15.22it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1725, train_loss: 0.00154, val_loss: 0.02458, pearson: 0.80110\n","validation elasped time:  36.4\n","total elasped time:  2.12e+03\n","[0.8154666896091781, 0.808456609315501]\n","Mean: 0.8119616494623396\n","*** FOLD 3 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1741/1741 [06:32<00:00,  4.44it/s, Epoch=0, LR=0.000913, Loss=0.0282, TotalLoss=0.0303]\n","100%|██████████| 539/539 [00:35<00:00, 15.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1741, train_loss: 0.02817, val_loss: 0.03268, pearson: 0.81797\n","Model Inproved: 0 ----> 0.8179745539673078\n","validation elasped time:  38.3\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [06:29<00:00,  4.47it/s, Epoch=1, LR=0.000665, Loss=0.00633, TotalLoss=0.0227]\n","100%|██████████| 539/539 [00:35<00:00, 15.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1741, train_loss: 0.00633, val_loss: 0.02281, pearson: 0.81776\n","validation elasped time:  35.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [06:29<00:00,  4.47it/s, Epoch=2, LR=0.000352, Loss=0.0162, TotalLoss=0.0182]\n","100%|██████████| 539/539 [00:35<00:00, 15.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1741, train_loss: 0.01618, val_loss: 0.02165, pearson: 0.82771\n","Model Inproved: 0.8179745539673078 ----> 0.8277080320404534\n","validation elasped time:  38.5\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [06:32<00:00,  4.43it/s, Epoch=3, LR=9.76e-5, Loss=0.00773, TotalLoss=0.015]\n","100%|██████████| 539/539 [00:36<00:00, 14.88it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1741, train_loss: 0.00773, val_loss: 0.02221, pearson: 0.82525\n","validation elasped time:  36.2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1741/1741 [06:31<00:00,  4.44it/s, Epoch=4, LR=0, Loss=0.0051, TotalLoss=0.0126]\n","100%|██████████| 539/539 [00:35<00:00, 15.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1741, train_loss: 0.00510, val_loss: 0.02245, pearson: 0.82353\n","validation elasped time:  35.8\n","total elasped time:  2.14e+03\n","[0.8154666896091781, 0.808456609315501, 0.8277080320404534]\n","Mean: 0.8172104436550441\n","*** FOLD 4 / 4***\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 1678/1678 [06:18<00:00,  4.44it/s, Epoch=0, LR=0.000913, Loss=0.0153, TotalLoss=0.0308]\n","100%|██████████| 602/602 [00:39<00:00, 15.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Step 1678, train_loss: 0.01534, val_loss: 0.02690, pearson: 0.78263\n","Model Inproved: 0 ----> 0.7826325311809951\n","validation elasped time:  42.8\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [06:16<00:00,  4.46it/s, Epoch=1, LR=0.000665, Loss=0.0226, TotalLoss=0.023]\n","100%|██████████| 602/602 [00:39<00:00, 15.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 2, Step 1678, train_loss: 0.02262, val_loss: 0.02495, pearson: 0.78863\n","Model Inproved: 0.7826325311809951 ----> 0.7886330095101691\n","validation elasped time:  42.7\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [06:16<00:00,  4.46it/s, Epoch=2, LR=0.000353, Loss=0.0155, TotalLoss=0.0184]\n","100%|██████████| 602/602 [00:39<00:00, 15.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 3, Step 1678, train_loss: 0.01549, val_loss: 0.02586, pearson: 0.79555\n","Model Inproved: 0.7886330095101691 ----> 0.7955494593586159\n","validation elasped time:  43.2\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [06:17<00:00,  4.45it/s, Epoch=3, LR=9.77e-5, Loss=0.0115, TotalLoss=0.0151]\n","100%|██████████| 602/602 [00:39<00:00, 15.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 4, Step 1678, train_loss: 0.01146, val_loss: 0.02525, pearson: 0.79051\n","validation elasped time:  39.9\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1678/1678 [06:16<00:00,  4.45it/s, Epoch=4, LR=0, Loss=0.00182, TotalLoss=0.0127]\n","100%|██████████| 602/602 [00:40<00:00, 14.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 5, Step 1678, train_loss: 0.00182, val_loss: 0.02561, pearson: 0.78949\n","validation elasped time:  40.2\n","total elasped time:  2.09e+03\n","[0.8154666896091781, 0.808456609315501, 0.8277080320404534, 0.7955494593586159]\n","Mean: 0.8117951975809371\n"]}],"source":["# ----------------------------------------------\n","# Main Loop\n","# ----------------------------------------------\n","val_scores = []\n","oof_df = pd.DataFrame()\n","\n","for fold in range(CFG.num_fold): \n","    print(f\"*** FOLD {fold+1} / {CFG.num_fold}***\")\n","\n","    save_path = f\"{CFG.out_path}/model_{fold+1}.pth\"\n","\n","    train_data = train_df[train_df['fold'] != fold]\n","    valid_data = train_df[train_df['fold'] == fold]\n","    train_set = TrainDataset(train_data)\n","    valid_set = TrainDataset(valid_data)\n","\n","    train_loader = DataLoader(train_set,\n","                            batch_size=CFG.train_batch_size,\n","                            shuffle=True,\n","                            drop_last=True,\n","                            num_workers=2,\n","                            pin_memory=True)\n","    valid_loader = DataLoader(valid_set,\n","                            batch_size=CFG.valid_batch_size,\n","                            shuffle=False,\n","                            drop_last=False,\n","                            num_workers=2,\n","                            pin_memory=True)\n","\n","    model = PPPMModel().to(CFG.device)\n","    optimizer = create_optimizer_grouped_parameters(model)\n","    #optimizer = AdamW(model.parameters(), lr=CFG.learning_rate)\n","    scheduler = get_cosine_schedule_with_warmup(\n","        optimizer,\n","        num_training_steps=CFG.epochs*len(train_loader),\n","        num_warmup_steps=100\n","    )\n","\n","    val_score, val_preds = train_fn(model, save_path, train_loader, valid_loader, optimizer, scheduler=scheduler)\n","\n","    val_scores.append(val_score)\n","    valid_data['preds'] = val_preds\n","    oof_df = pd.concat([oof_df, valid_data])\n","\n","    del model\n","    torch.cuda.empty_cache()\n","\n","    print(val_scores)\n","    print(\"Mean:\", np.array(val_scores).mean())\n","    if CFG.fold1_only == True:\n","        if fold == 0:\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"nz0KfPOAXBbi","outputId":"c8ad5b01-db0a-4027-94ef-819b99c8ac74"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'for batch_idx, data in enumerate(valid_loader):\\n  print(batch_idx)\\n'"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"for batch_idx, data in enumerate(valid_loader):\n","  print(batch_idx)\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HQUyBAm0NDiF","outputId":"2865c9a8-1aa1-4dcf-c6ef-4c4bf105dd5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["fold0    0.815467\n","fold1    0.808457\n","fold2    0.827708\n","fold3    0.795549\n","oof      0.808823\n","dtype: float64\n"]}],"source":["scores = {f'fold{i}':j for i,j in enumerate(val_scores)}\n","scores['oof'] = np.corrcoef(oof_df['preds'], oof_df['score'])[0][1]\n","scores = pd.Series(scores)\n","print(scores)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"zmBZERwvNkCo"},"outputs":[],"source":["scores.to_csv(f'{CFG.out_path}/scores.csv')\n","oof_df.to_csv(f'{CFG.out_path}/oof_df.csv')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[{"file_id":"1w5uFoGdqnkIBeoZRlOuJFwlnjjsNbRTK","timestamp":1654169874663},{"file_id":"1omHuxNQsXsp9AqAdUHsc_dt9KtP20yMP","timestamp":1654168824854},{"file_id":"1GP-aM4gbJLt_K4PjctRHRgU-p7AjxvC6","timestamp":1654167290824},{"file_id":"1PQsBMoKIQEQSVPuMOKwMFHmzcHbel78W","timestamp":1654165080313},{"file_id":"1DIjKU3ktcrs9RfESQSO4Xf2DNCAmSECb","timestamp":1653339588896},{"file_id":"1y0dkP43iXyooLt43fdk3ElIC6ndubdxd","timestamp":1653303566583},{"file_id":"1HgfHxBWVNXFQQ-VgAxmpLDpzfmcsO7U3","timestamp":1653263004769},{"file_id":"1Bi1AdwFa2IrEpkW_vMGZkOATD45BfjF5","timestamp":1653256357852},{"file_id":"1oY_J27W0Uv7QkVRwUZytT1mrvRgDXe4L","timestamp":1653203615891},{"file_id":"1cAftaWxxDtH2724hCJr8n0e_5Xhj8mPy","timestamp":1653125565109},{"file_id":"1ENNIPhZgUOS4XtGZ_7JWBH-731sVuHGM","timestamp":1653095567105},{"file_id":"1BlfrktS37Y0Gzb1HsRKJI3SrfqrlHIaL","timestamp":1653020571389},{"file_id":"1xoLboFCuSvLYtqoCVkPkypRFhm5-FQ93","timestamp":1653001405922}],"mount_file_id":"1Uet16e_JjpPbyK2arnGanjjlSSSDhiXH","authorship_tag":"ABX9TyO8RFVUT9pgu+SMqdy6e0qd"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"02b773f093af4dde9ee495f4ed1bce8c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1075a3ae347d41399d7e0d2f30e632fa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"151e6ef3434a4c0d860c1a01413936a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1b57025a5322414f9af096844f5dfbbc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1eeeec1a8ef540b684d2b0536ec8b96b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f63c90aa0df459fa0890a7937f0e585":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd8788b006543d3b2206d56bc88f50b","placeholder":"​","style":"IPY_MODEL_981f6b3affae46eb9cb280d29b599433","value":" 52.0/52.0 [00:00&lt;00:00, 1.43kB/s]"}},"220c5226b678407e914f926728e14ab6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72d1289391b84e60913ed3d225daf2a3","IPY_MODEL_bfe499f531b743539ae901a19804048c","IPY_MODEL_294d517e75be4383ab059c4ee85a671f"],"layout":"IPY_MODEL_e06fb744a7284ab0a1a5cf14cee6a1d6"}},"225116e42e2942799492783f3b2603e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6f9b972d61d495d908962da340e2a61","IPY_MODEL_559924f78faf4f05a2bec5732e7a06db","IPY_MODEL_1f63c90aa0df459fa0890a7937f0e585"],"layout":"IPY_MODEL_ad4ea4ea59b9461e933f6f74a4e490de"}},"294d517e75be4383ab059c4ee85a671f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b0ff85cbdb14cd68ddb083e1dc1874c","placeholder":"​","style":"IPY_MODEL_fbe07cedba3a44caa3e2227af83f0294","value":" 354M/354M [00:06&lt;00:00, 60.6MB/s]"}},"3b19e5be0a5d49bc957a87de816e7fb5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4cf9db6cafbc48e7a0556e1df2df058c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"559924f78faf4f05a2bec5732e7a06db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02b773f093af4dde9ee495f4ed1bce8c","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85f292285ac041698da5c41d5eaa65a9","value":52}},"5d2b97d56e704003ab803590dfd240ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d937aba9ee0408c83c381a7cf62d897","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_151e6ef3434a4c0d860c1a01413936a9","value":579}},"5d937aba9ee0408c83c381a7cf62d897":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ce1dbac9dff4214919611f3ddd899db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e5ef74bf7c74a06896073515f81476f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72d1289391b84e60913ed3d225daf2a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_923d1c215c124da295cdd1b2bf67ec52","placeholder":"​","style":"IPY_MODEL_1b57025a5322414f9af096844f5dfbbc","value":"Downloading: 100%"}},"765322cb909949ed8a0ca577252f8ae6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cd8788b006543d3b2206d56bc88f50b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f401f6e1f1e4db8b550db2b40edf0db":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97df9c4d69694a10ae1e71df55a7d13e","placeholder":"​","style":"IPY_MODEL_d2f6cea6f56a40abb824d127323a9252","value":"Downloading: 100%"}},"85f292285ac041698da5c41d5eaa65a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"895ff65933324d7799fe5f86b8bdc36d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4cf9db6cafbc48e7a0556e1df2df058c","placeholder":"​","style":"IPY_MODEL_ff350ef3ec134427bb7c2a4ef1acc65b","value":"Downloading: 100%"}},"923d1c215c124da295cdd1b2bf67ec52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97df9c4d69694a10ae1e71df55a7d13e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"981f6b3affae46eb9cb280d29b599433":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b0ff85cbdb14cd68ddb083e1dc1874c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fe1769a5fdf42adb2d63fd50d7c9689":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f401f6e1f1e4db8b550db2b40edf0db","IPY_MODEL_f9ea242396e94f0fbac538f37870aaed","IPY_MODEL_f8b7922bb6d24e07ab2aeb9e46f3af47"],"layout":"IPY_MODEL_1075a3ae347d41399d7e0d2f30e632fa"}},"a34ebc39cacc4fd09864b63404277d13":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad4ea4ea59b9461e933f6f74a4e490de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adab36b6656447ccb2d2b076caf63f60":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b9f21bb4d6db4c54ba0a007a387c37b0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be1e4f6a5db04a6ead8af8e63e080b8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_895ff65933324d7799fe5f86b8bdc36d","IPY_MODEL_5d2b97d56e704003ab803590dfd240ff","IPY_MODEL_d53f9c72ea70448b9863f220005eb19b"],"layout":"IPY_MODEL_a34ebc39cacc4fd09864b63404277d13"}},"bfe499f531b743539ae901a19804048c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e5ef74bf7c74a06896073515f81476f","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adab36b6656447ccb2d2b076caf63f60","value":371146213}},"c84d82dea3b945aab7d63102ec400261":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2f6cea6f56a40abb824d127323a9252":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d53f9c72ea70448b9863f220005eb19b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ce1dbac9dff4214919611f3ddd899db","placeholder":"​","style":"IPY_MODEL_ec1820ca43d3401fa27524ca34e0425d","value":" 579/579 [00:00&lt;00:00, 17.6kB/s]"}},"d6f9b972d61d495d908962da340e2a61":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9f21bb4d6db4c54ba0a007a387c37b0","placeholder":"​","style":"IPY_MODEL_3b19e5be0a5d49bc957a87de816e7fb5","value":"Downloading: 100%"}},"d8eddf3fba024b5698b7b163d94299f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e06fb744a7284ab0a1a5cf14cee6a1d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1820ca43d3401fa27524ca34e0425d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8b7922bb6d24e07ab2aeb9e46f3af47":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eeeec1a8ef540b684d2b0536ec8b96b","placeholder":"​","style":"IPY_MODEL_c84d82dea3b945aab7d63102ec400261","value":" 2.35M/2.35M [00:00&lt;00:00, 6.49MB/s]"}},"f9ea242396e94f0fbac538f37870aaed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_765322cb909949ed8a0ca577252f8ae6","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8eddf3fba024b5698b7b163d94299f6","value":2464616}},"fbe07cedba3a44caa3e2227af83f0294":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ff350ef3ec134427bb7c2a4ef1acc65b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}